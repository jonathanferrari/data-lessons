{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "951bf296",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <h1>\n",
    "        Hypothesis Testing\n",
    "    </h1>\n",
    "</center>\n",
    "\n",
    "<center>\n",
    "    <h3>\n",
    "        <i>\n",
    "            by \n",
    "            <a href=\"https://jonathanferrari.com\">\n",
    "                Jonathan Ferrari\n",
    "            </a>\n",
    "        </i>\n",
    "    </h3>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871d0bcd",
   "metadata": {},
   "source": [
    "This notebook will go over the general steps on how to do a hypothesis test and go through a few examples. For questions, concerns, or anything else relevant to this notebook, please [contact me](https://jonathanferrari.com/contact)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c2021f",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c08afa",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49b641f",
   "metadata": {},
   "source": [
    "Here we will import some libraries needed for this demonstration. Make sure you run this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0392ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datascience import *\n",
    "from ipywidgets import *\n",
    "from utils import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff382dbe",
   "metadata": {},
   "source": [
    "# General Procedure for Hypothesis Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ba31fb",
   "metadata": {},
   "source": [
    "Here is the general procedure in completing a hypothesis test:\n",
    "\n",
    "### Observation <a id=\"obs\"/>\n",
    "1. We **notice something weird** about an procedure or problem.\n",
    "    1. Most of the time, this is a value that we see that is weird to us.\n",
    "    \n",
    "### Reason <a id=\"why\"/>\n",
    "2. We need to come up with **ideas about why** this is happening.\n",
    "    1. One possibility is that this weird thing just happened **due to chance**. Even though it looks weird it is fair to assume that the result could have happened by chance.\n",
    "        1. This is the ***Null Hypothesis***.\n",
    "            1. It is the hypothesis we will simulate under.\n",
    "    2. Another possibility is that the difference is **not due to chance**, and that in fact, there is something **other than randomness that is causing** the value to be weird.\n",
    "        1. This is the ***Alternative Hypothesis***.\n",
    "            1. It is the hypothesis we do not simulate under.\n",
    "            \n",
    "### Weirdness <a id=\"weird\"/>\n",
    "3. We need a way to test our ideas\n",
    "    1. We need a ***test statistic*** that will quantify **how \"weird\" an event is**.\n",
    "        1. There are many to choose from including: *absolute difference*, *TVD*, *proportions*, etc.\n",
    "            1. Different test statistics will be better for different situations. It is your job to pick one that will work well.\n",
    "            \n",
    "### How Weird <a id=\"hw\"/>\n",
    "4. We need to quantify how weird our original event from $1$ is.\n",
    "     1. We use our test statistic from $3$ to calculate a number.\n",
    "         1. This number is called our ***observed value***.\n",
    "\n",
    "### Simulation <a id=\"sim\"/>\n",
    "5. We need to know **how often** weird things happen in this event.\n",
    "    1. We first **define a function**.\n",
    "        1. This function **simulates** the event happening *under the Null Hypothesis*.\n",
    "            1. Then, we calculate our test **statistic on this random event**.\n",
    "\n",
    "### Repetition  <a id=\"rep\"/>\n",
    "6. We want to simulate an event **many times**.\n",
    "    1. We want to **keep track** of our test statistic for each randomly simulated event.\n",
    "        1. We can do this by creating an **empty array** initially.\n",
    "            1. We the **append each test statistic _value_** to the array in a `for` loop.\n",
    "\n",
    "### Comparison  <a id=\"comp\"/>\n",
    "7. We need to compare **how weird** our *observed value*, **compared to** the *randomly generated statistic values*.\n",
    "    1. To do this we calculate the **proportion of times** where our **observed** value was **weirder than** each **random statistic value**.\n",
    "        1. We can **sum** the amount of **times it was more weird**, then **divide** by the **total count** of random test statistics.\n",
    "            1. This proportion is called our ***p-value***.\n",
    "\n",
    "### Conclusion  <a id=\"conc\"/>\n",
    "8. We need to decide if our observed value (the weird observation) is **weird enough**.\n",
    "    1. To do this we **compare with a cutoff**.\n",
    "        1. If $\\text{p-value} \\leq \\text{cutoff}$ we **reject the Null Hypothesis**.\n",
    "        2. Otherwise, we **fail to reject the Null Hypothesis**.\n",
    "            1. _Note: We cannot **accept the Alternative**, as we cannot **prove** that it is true._\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0b419c",
   "metadata": {},
   "source": [
    "# Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3524e337",
   "metadata": {},
   "source": [
    "Now that we have a framework on how to proceed, lets look at a few examples!\n",
    "\n",
    "<div class=\"alert alert-box alert-info\">\n",
    "    <p>\n",
    "        If you click on the links in each of the sub-sections below, they will bring you to the respective explanation above\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580fd324",
   "metadata": {},
   "source": [
    "## Example 1: Hand Raising\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1f6d6b",
   "metadata": {},
   "source": [
    "### [Observation](#obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f8b54f",
   "metadata": {},
   "source": [
    "Jonathan is a TA for Data 8, and notices that his students raise their left hands more often than their right hands.\n",
    "\n",
    "He has **$40$ students**, and by his count, **$27$ raise their left** hand and **$13$ raise their right hand**.\n",
    "\n",
    "Let's also define some variables to track the numbers in this observed event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672e69fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_count = 40\n",
    "observed_left = 27\n",
    "observed_right = 13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ca8919",
   "metadata": {},
   "source": [
    "### [Reason](#why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848a8836",
   "metadata": {},
   "source": [
    "Jonathan comes up with two ideas on what could be happening\n",
    "\n",
    "- **Idea 1:** _Null Hypothesis_\n",
    "    - Students raise their left and right hands the same amount, any observed difference is due to chance.\n",
    "- **Idea 2:** _Alternative Hypothesis_\n",
    "    - Students do not raise their left and right hands equally, the observed difference is due to something other than chance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4674b02c",
   "metadata": {},
   "source": [
    "### [Weirdness](#weird)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "38baa340",
   "metadata": {},
   "source": [
    "He now must define a test statistic. He decides to do the _Average Distance from Expectation (ADE)_. This will be computed as follows:\n",
    "\n",
    "$$\\frac{|\\text{count of left hands} - \\text{count of right hands}|}{2}$$\n",
    "\n",
    "He could have chosen something else such as:\n",
    "\n",
    "$$ |\\text{count of left hands} - 20|$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "910acf0f",
   "metadata": {},
   "source": [
    "Let's define a function called `ade` to help us compute this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59919f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ade(left, right):\n",
    "    return abs(left - right)/2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568be58a",
   "metadata": {},
   "source": [
    "### [How Weird](#hw)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "03408272",
   "metadata": {},
   "source": [
    "Now let's calculate our observed value using the `ade` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5fdb48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "observed = ade(observed_left, observed_right)\n",
    "show(f\"The observed value is: {observed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ae3e0d",
   "metadata": {},
   "source": [
    "### [Simulation](#sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36690eb7",
   "metadata": {},
   "source": [
    "Now we need to define a function called `simulate` which will simulate one event under the null hypothesis, and give us our test statistic for that event.\n",
    "\n",
    "This function randomly choses `\"left\"` or `\"right\"` 40 times. It then tells us how many left and right hands it picked, with left first then right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe05381",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate():\n",
    "    hands = make_array(\"left\", \"right\")\n",
    "    choices = np.random.choice(hands, student_count)\n",
    "    left_count = sum(choices == \"left\")\n",
    "    right_count = sum(choices == \"right\")\n",
    "    return make_array(left_count, right_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9017c04b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-box alert-info\">\n",
    "    <p>\n",
    "        Run the cell below a few times to check out what kind of values we are getting as we simulate under the null hypothesis.\n",
    "    </p>\n",
    "</div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20a0c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87653e9d",
   "metadata": {},
   "source": [
    "### [Repetition](#rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96de856d",
   "metadata": {},
   "source": [
    "Now, under the null hypothesis, let's simulate $10,000$ random events and collect the test statistic values for each one in an array called `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb477e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = make_array()\n",
    "trials = 10_000\n",
    "for i in np.arange(trials):\n",
    "    one_trial = simulate()\n",
    "    one_stat = ade(one_trial.item(0), one_trial.item(1))\n",
    "    results = np.append(results, one_stat)\n",
    "show(f\"Collected all {trials:,} statistics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffb318f",
   "metadata": {},
   "source": [
    "Great, now that we have all the statistics, let's compare these values with our observed value. \n",
    "\n",
    "As an intermediate step, we'll create a table with the data in it\n",
    "\n",
    "Check out the histogram below \n",
    "\n",
    "<div class=\"alert alert-box alert-info\">\n",
    "    <p>\n",
    "        <i>Note:</i> Don't worry about understanding the code below, just focus on the graph!\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66c72ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "hands = Table().with_column(\"Hand ADE\", results)\n",
    "bin_range = np.arange(max(results))\n",
    "fig = hands.ihist(show = False, unit = \"hand\", bins = bin_range, title = \"ADE of Hands\")\n",
    "show(\"You can hover over each bar to find the exact percent!\")\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627151eb",
   "metadata": {},
   "source": [
    "### [Comparison](#comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14af520b",
   "metadata": {},
   "source": [
    "Now, lets compute the p-value of the data! We can do this using the following formula: \n",
    "\n",
    "$$\\frac{\\text{number of simulations more extreme than observed value}}{\\text{number of simulations}}$$\n",
    "\n",
    "We'll compute our p-value below (in the first line), and plot a histogram showing it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e44d85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_value = sum(results >= observed)/len(results)\n",
    "fig = hands.ihist(\"Hand ADE\", bins = bin_range, show = False, unit = \"hand\",\n",
    "                  title = f\"P-Value: {p_value} | Observed Value: {observed}\")\n",
    "fig = add_observed(fig, observed)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b97a2b",
   "metadata": {},
   "source": [
    "### [Conclusion](#conc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361cf2fd",
   "metadata": {},
   "source": [
    "Now that we've calculated the p-value, we can come to a conclusion. We need to set a _\"cutoff\"_ value. This is the value we use to determine if we can reject the null hypothesis. Convention says we should use $0.05$, which is what we will use, but this number can be different in certain cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b2b89c",
   "metadata": {},
   "source": [
    "In the cell below, we will run some code to determine if we can reject the null hypothesis!\n",
    "\n",
    "Try changing the cutoff value and see if the cell outputs something different!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0c7853",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 0.05\n",
    "if p_value < cutoff:\n",
    "    show(f\"We can reject the null hypothesis, because our p-value, {p_value} is less than the cutoff, {cutoff}\")\n",
    "else:\n",
    "    show(f\"We cannot reject the null hypothesis because our p-value, {p_value} is not less than the cutoff {cutoff}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3de3f5e",
   "metadata": {},
   "source": [
    "### Example 1: Addendum \n",
    "\n",
    "One thing to note is that our test statistic could have been quite different and we may have still gotten the same answer. \n",
    "\n",
    "Run the cell below and try selecting a different test statistic, and use the slider to change the p-value cutoff, and see what result you get!\n",
    "\n",
    "**Note:** The cell will take a few moments to render, so be patient with it!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7703403b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-box alert-info\">\n",
    "    <p>\n",
    "        <i>Note:</i> Don't worry about understanding the code below, just focus on the result!\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ab7174",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "@interact(statistic_function = Dropdown(options = pairs, description = \"Function:\"),\n",
    "          cutoff = FloatSlider(min = 0, max = 0.5, value = 0.05, step = 0.05, description = \"Cutoff:\"))\n",
    "def simulate_with_different_statistics(statistic_function, cutoff):\n",
    "    observed = statistic_function(observed_left, observed_right)\n",
    "    results = make_array()\n",
    "    trials = 10_000\n",
    "    for i in np.arange(trials):\n",
    "        one_trial = simulate()\n",
    "        one_stat = statistic_function(one_trial.item(0), one_trial.item(1))\n",
    "        results = np.append(results, one_stat)\n",
    "    show(f\"Collected all {trials:,} statistics\")\n",
    "    hands = Table().with_columns(\"Hand Statistic\", results)\n",
    "    p_value = sum(results >= observed)/len(results)\n",
    "    if all_ints(results):\n",
    "        bin_range = np.arange(min(results), max(results) + 1)\n",
    "    else:\n",
    "        bin_range = None\n",
    "    fig = hands.ihist(\"Hand Statistic\", show = False, bins = bin_range,\n",
    "                      title = f\"P-Value: {p_value:.3f} | Observed Value: {observed:.3f}\")\n",
    "    fig = add_observed(fig, observed, f\"Observed Value: {observed:.3f}\")\n",
    "    fig.show()\n",
    "    cutoff = 0.05\n",
    "    if p_value < cutoff:\n",
    "        show(f\"We can reject the null hypothesis, because our p-value, {p_value:.3f} is less than the cutoff, {cutoff}\")\n",
    "    else:\n",
    "        show(f\"We cannot reject the null hypothesis because our p-value, {p_value:.3f} is not less than the cutoff {cutoff}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b8311c",
   "metadata": {},
   "source": [
    "One important takeaway is many of those test statistics had almost the exact same p-value! This helps illustrate the fact that as long as our test statistic makes sense and we are consistent, we can use many different values! However, importantly for two of the options our p-values were very different. This can go to show how using a bad statistic function can lead us to an incorrect conclusion, so we need to be careful"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f723a3",
   "metadata": {},
   "source": [
    "## Example 2: Population and Politics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15da69a",
   "metadata": {},
   "source": [
    "### [Observation](#obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec3fadc",
   "metadata": {},
   "source": [
    "We have some data relating to U.S. counties in two tables, `population` and `political`. Each table has two columns, the first of both is a unique code for each county. The second column in `population` is the population of that county, and the second column in `political` is the winner of the 2020 Presidential election in that county (e.g., `\"Trump\"` or `\"Biden\"`). \n",
    "\n",
    "Lets use `.join` to get the data into one table!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86c4811",
   "metadata": {},
   "outputs": [],
   "source": [
    "population = Table.read_table('county-population.csv')\n",
    "population.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06790362",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "political = Table.read_table('county-politics.csv')\n",
    "political.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcefb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "counties = political.join(\"fips\", population, \"fips\")\n",
    "counties.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd37a283",
   "metadata": {},
   "source": [
    "We would like to do a little bit of analysis of this data, specifically we want to look at the average population of counties that voted for Trump, and ones that voted for Biden.\n",
    "\n",
    "To do this we will use `.group`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ed90e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pop_by_party = counties.group(\"winner\", np.average).drop(\"fips average\")\n",
    "pop_by_party"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cca103a",
   "metadata": {},
   "source": [
    "We can see there is a very large difference here, specifically, on average counties that voted for Biden were $7.33$ times larger than those that voted for Trump.\n",
    "\n",
    "This will be our \"weird\" observation for this example. We should record these numbers to calculate our observed value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4247d986",
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_dem = pop_by_party.column(1).item(0)\n",
    "observed_rep = pop_by_party.column(1).item(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44dc1e3c",
   "metadata": {},
   "source": [
    "### [Reason](#why)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd288eb",
   "metadata": {},
   "source": [
    "We can come up with two ideas on what could be happening\n",
    "\n",
    "- **Idea 1:** _Null Hypothesis_\n",
    "    - The counties that vote democratic and republican have similar population sizes; any difference is due to chance\n",
    "- **Idea 2:** _Alternative Hypothesis_\n",
    "    - Counties that have vote democratic have larger populations than those which vote republican."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdd430e",
   "metadata": {},
   "source": [
    "### [Weirdness](#weird)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2f88f5",
   "metadata": {},
   "source": [
    "Again, let's define a test statistic. Here we want to use a ***one-sided statistic*** because our alternative hypothesis specifies that we think democratic counties have more people on average than republican counties.\n",
    "\n",
    "We could pick a few different statistics, but the simplest is the difference between the democratic average population, and the republican average population, formulated as follows:\n",
    "\n",
    "$$\\text{average democratic county population} - \\text{average republican county population}$$\n",
    "\n",
    "We could also do the ratio of democratic average population over the republican average population:\n",
    "\n",
    "$$\\frac{\\text{average democratic county population}}{\\text{average republican county population}}$$\n",
    "\n",
    "In this case, we will opt for simplicity and choose the difference (the first statistic)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129db50b",
   "metadata": {},
   "source": [
    "Let's define a function called `pop_diff` to help us compute this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3f35bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pop_diff(dem, rep):\n",
    "    return dem - rep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5b7107",
   "metadata": {},
   "source": [
    "### [How Weird](#hw)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dd4c8220",
   "metadata": {},
   "source": [
    "Now let's calculate our observed value using the `pop_diff` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8bff43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "observed = pop_diff(observed_dem, observed_rep)\n",
    "show(f\"The observed value is: {observed:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd0422d",
   "metadata": {},
   "source": [
    "### [Simulation](#sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f6615f",
   "metadata": {},
   "source": [
    "Now we need to define a function called `simulate` which will simulate one event under the null hypothesis, and give us our test statistic for that event. In this case since we have data with labels, we will do an **A/B test**.\n",
    "\n",
    "This function shuffles the labels of the `counties` table and returns the democratic and republican average populations under the null hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b37b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate():\n",
    "    shuffled_labels = counties.sample(with_replacement = False).column(1)\n",
    "    values = counties.column(2)\n",
    "    new_counties = Table().with_columns(\"population\", values, \"winner\", shuffled_labels)\n",
    "    grouped = new_counties.group(\"winner\", np.average)\n",
    "    dem = grouped.column(1).item(0)\n",
    "    rep = grouped.column(1).item(1)\n",
    "    return make_array(dem, rep)\n",
    "simulate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441c9934",
   "metadata": {},
   "source": [
    "Then, to calculate an observed test statistic, we simply apply the `pop_diff` function!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58a57c6",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-box alert-info\">\n",
    "    <p>\n",
    "        Run the cell below a few times to check out what kind of values we are getting as we simulate under the null hypothesis.\n",
    "    </p>\n",
    "</div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9e10b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_value = simulate()\n",
    "pop_diff(sim_value.item(0), sim_value.item(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8961dd5e",
   "metadata": {},
   "source": [
    "### [Repetition](#rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae01db1",
   "metadata": {},
   "source": [
    "Now, under the null hypothesis, let's simulate $1,000$ random events and collect the test statistic values for each one in an array called `results`.\n",
    "\n",
    "Fair warning, this cell takes a little while to run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2132a849",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = make_array()\n",
    "trials = 1_000\n",
    "for i in np.arange(trials):\n",
    "    one_trial = simulate()\n",
    "    one_stat = pop_diff(one_trial.item(0), one_trial.item(1))\n",
    "    results = np.append(results, one_stat)\n",
    "show(f\"Collected all {trials:,} statistics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f9cdfd",
   "metadata": {},
   "source": [
    "Great, now that we have all the statistics, let's compare these values with our observed value. \n",
    "\n",
    "As an intermediate step, we'll create a table with the data in it\n",
    "\n",
    "Check out the histogram below \n",
    "\n",
    "<div class=\"alert alert-box alert-info\">\n",
    "    <p>\n",
    "        <i>Note:</i> Don't worry about understanding the code below, just focus on the graph!\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e49420",
   "metadata": {},
   "outputs": [],
   "source": [
    "votes = Table().with_column(\"Population Differences\", results)\n",
    "fig = votes.ihist(show=False, unit=\"person\", title = \"Difference of Average Population\")\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4773b18c",
   "metadata": {},
   "source": [
    "### [Comparison](#comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b01230",
   "metadata": {},
   "source": [
    "Now, lets compute the p-value of the data! We can do this using the following formula: \n",
    "\n",
    "$$\\frac{\\text{number of simulations more extreme than observed value}}{\\text{number of simulations}}$$\n",
    "\n",
    "We'll compute our p-value below (in the first line), and plot a histogram showing it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72415723",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_value = sum(results >= observed)/len(results)\n",
    "fig = votes.ihist(\"Population Differences\", show = False, \n",
    "                  title = f\"P-Value: {p_value} | Observed Value: {observed:,.2f}\")\n",
    "fig = add_observed(fig, observed, f\"Observed Value:{observed:,.2f}\")\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e8f1e6",
   "metadata": {},
   "source": [
    "### [Conclusion](#conc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b8f761",
   "metadata": {},
   "source": [
    "***Note:*** Here our p-value is $0.0$ because out of all of our trials, none had a more extreme value than the observed value. \n",
    "\n",
    "Hence, no matter what we set our cutoff to, we will be able to reject the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a26e7b",
   "metadata": {},
   "source": [
    "# Conclusion and Feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57248878",
   "metadata": {},
   "source": [
    "Now you've gone through the general steps for hypothesis testing, and two examples. Hopefully you had half as much fun dunning through the notebook as I had making it!\n",
    "\n",
    "For further clarification on hypothesis testing, please see [*Foundations of Data Science* â€“ Chapter 11: Testing Hypotheses](https://inferentialthinking.com/chapters/11/Testing_Hypotheses.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1916c90",
   "metadata": {},
   "source": [
    "I would also appreciate any feedback you have on this lesson. You can access the feedback form by running the cell below and clicking the button that appears! Thanks :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03c7315",
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback_button()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
